{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1e0_8K6GTkG"
   },
   "source": [
    "# Практическое ДЗ-2. Использование ALS для построения рекомендательной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy0CPB5oGTkI"
   },
   "source": [
    "В этой задаче мы построим простую рекомендательную модель на основе малоранговых приближений разреженных матриц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rQ_Xh0zGTkI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ0M75d1GTkI"
   },
   "source": [
    "### Подготовка датасета\n",
    "Загрузите датасет movielens10m с [grouplens.org](https://grouplens.org/datasets/movielens/10m/) и положите архив в папку `data`. Нас будет интересовать файл `ratings.dat`, в котором собраны оценки пользователями различных фильмов с сервиса movielens.org. Вытащим этот файл из архива. Как можно узнать из соответствующей [странички](http://files.grouplens.org/datasets/movielens/ml-10m-README.html#file_desc), этот файл имеет формат `UserID::MovieID::Rating::Timestamp`. Сразу позаботимся, чтобы id пользователей и фильмов начинались с нуля (в самом файле индексация с единицы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ALFIBL2GTkJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "user_ids = []\n",
    "movie_ids = []\n",
    "ratings = []\n",
    "with zipfile.ZipFile('data/ml-10m.zip') as archive:\n",
    "    with archive.open('ml-10M100K/ratings.dat') as f:\n",
    "        for l in f:\n",
    "            user, movie, rating, _ = l.split(b'::')\n",
    "            user_ids.append(int(user) - 1)\n",
    "            movie_ids.append(int(movie) - 1)\n",
    "            ratings.append(float(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwlRKeriGTkJ"
   },
   "source": [
    "Составим матрицу рейтингов $A \\in \\mathbb R^{m \\times n}$, индексируемую номером пользователем и номером фильма.\n",
    "Для простоты мы будем делить отзывы только на положительные (`Rating >= 4` &mdash; $A_{i,j}=1$) и отрицательные (`Rating < 4` &mdash; $A_{i,j} = 0$), таким образом, матрица у нас получится состоящей только из нулей и единиц.\n",
    "Обратите внимание, что матрица будет разреженной, так как средний пользователь оценил относительно мало фильмов. Поэтому мы будем пользоваться библиотекой `scipy.sparse`. Хранить матрицу мы будем в формате хранения разреженных матриц [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)), который поддерживает матричное умножение на numpy массивы: ```A @ X ```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFQAXNIFGTkJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "A = csr_matrix((np.array(ratings) >= 4, (user_ids, movie_ids)), dtype=np.float32)\n",
    "A.eliminate_zeros()\n",
    "print(\"Shape:\", A.shape)\n",
    "print(\"Ratio of nonzero elements:\", A.nnz / (A.shape[0] * A.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odCs6tjeGTkK"
   },
   "source": [
    "Отделим некоторое количество пользователей для последующей проверки. Используем стандартное разбиение train/test 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrN0pCEBGTkK"
   },
   "outputs": [],
   "source": [
    "n_users, n_movies = A.shape\n",
    "n_test = int(n_users * 0.2)\n",
    "n_train = n_users - n_test\n",
    "idx = np.arange(n_users)\n",
    "np.random.shuffle(idx)\n",
    "test_idx, train_idx = idx[:n_test], idx[n_test:]\n",
    "A_test, A_train = A[test_idx,:], A[train_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH-aMFybGTkK"
   },
   "source": [
    "Далее в задаче мы будем строить рекомендации пользователям на основе малорангового приближения матрицы $A$ (матрицы $A_{train}$ в рамках обозначений выше). \n",
    "Обратим внимание, что из-за ограничений по памяти мы не можем сформировать матрицу $A$ в виде numpy массива, а значит теряем доступ к ```np.linalg.svd```. Поэтому мы будем реализовывать метод ALS, в котором требуется только умножение на матрицы $A$ и $A^\\top$, что поддерживается разреженными форматами хранения матриц (CSR, COO и тд).\n",
    "\n",
    "### a. (35 баллов) Вычисление вспомогательных функционалов\n",
    "\n",
    "  1. **(15 баллов)** Напомним, что в методе ALS решается задача минимизации функционала $f(U, V^\\top) = \\|A - UV^\\top\\|_F$ по всем $U \\in \\mathbb R^{m \\times r}$ и $V  \\in \\mathbb R^{n \\times r}$. Первым делом вам нужно будет написать функцию `als_functional` для вычисления оптимизируемого функционала $\\|A - UV^\\top\\|_F$ для заданных $A$, $U$, $V^\\top$. Заметьте, что прямое вычисление этой нормы &mdash; очень трудоёмкая задача, ведь разность будет плотной матрицей. Для того, чтобы эффективно вычислить норму разности, распишите $\\|A - UV^\\top\\|_F^2$ через скалярное произведение $\\langle X,Y \\rangle_F = \\mathrm{Tr}\\,(X^\\top Y)$, выполните алгебраические преобразования и покажите, как эффективно вычислить каждый член в полученном выражении. Имеется в виду, что ни на каком этапе вы не должны явно формировать плотные матрицы размеров `A.shape` (хотя numpy, скорее всего, и откажется аллоцировать 37 ГБ под такой массив).\n",
    "  \n",
    "  **Замечание**: не используйте циклы по ненулевым элементам разреженной матрицы $A$. Убедитесь, что в ваши формулы входит только умножение на матрицы $A$ или $A^\\top$, на которые можно умножать посредством @; либо умножения сложности $O(mr^2), O(nr^2)$. Также отметим, что норма матрицы $A$ уже дана, заново её вычислять не надо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmeXXvh4GTkL"
   },
   "outputs": [],
   "source": [
    "def als_functional(A, A_norm, U, VT):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: sparse 2D array\n",
    "            A_norm: Frobenius norm of A\n",
    "            U, VT: 2D arrays such that U @ VT approximates A\n",
    "        Output\n",
    "            ||A - U VT||_F\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEQ_TfYC_Myv"
   },
   "source": [
    "**Замечание:** Если вы не сможете выполнить следующие два пункта, можете их пропустить. Они не являются обязательными для следующих заданий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pynl_j3Q4EF5"
   },
   "source": [
    "  2. **(10 баллов)** *Расстоянием от подпространства* $L_1 \\subset \\mathbb{R}^m$ *до подпространства* $L_2 \\subset \\mathbb{R}^m$ будем называть число $\\|(I - P(L_1)) P(L_2)\\|_2$, где $P(L_i)$ &mdash; ортопроектор на $L_i$. Функция несимметричная, так что будьте осторожны с расстановкой аргументов. Опишите алгоритм вычисления расстояния от $\\mathrm{Im}(U_1)$ до $\\mathrm{Im}(U_2)$ для заданных матриц $U_1, U_2 \\in \\mathbb{R}^{m \\times r}$ с ортонормированными столбцами (т.е. $U_i^\\top U_i = I$). Алгоритм должен иметь сложность $O(mr^2)$. **Подсказка.** Воспользуйтесь техникой малоранговой арифметики, описанной на соответствующих лекции и семинаре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IibP7Xl74Kp8"
   },
   "source": [
    "**YOUR WORDS GO HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3FlQJMG4NUo"
   },
   "source": [
    "  3. **(10 баллов)** Напишите функцию `dist_between_subspaces`, принимающую на вход матрицы $U_1, U_2 \\in \\mathbb{R}^{m\\times r}$ с ортонормированными столбцами, и возвращающую расстояние от $\\mathrm{Im}(U_1)$ до $\\mathrm{Im}(U_2)$. Сложность алгоритма должна быть $O(mr^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-5vadb0-pco"
   },
   "outputs": [],
   "source": [
    "def dist_between_subspaces(U1, U2):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            U1, U2: matrices with orthonormal columns\n",
    "        Output\n",
    "            Distance from Im(U1) to Im(U2)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLxAu8r9GTkM"
   },
   "source": [
    "### b. (30 баллов) Метод ALS\n",
    "Реализуйте метод ALS (alternating least squares) с ортогонализацией (см. лекции).\n",
    "\n",
    "Вам будет необходимо вернуть две матрицы: $U$ и $V^\\top$, образующие скелетное разложение результирующего приближения; где $V^\\top$ имеет ортонормированные строки. Также нужно вернуть 3 списка:\n",
    "\n",
    "\n",
    "*   Список значений функционала $f(U_k, V^\\top_k) = \\|A - U_k V^\\top_k\\|_F$\n",
    "\n",
    "*   Список изменений значений функционала $\\delta_k = f(U_{k-1}, V^\\top_{k-1}) - f(U_k, V^\\top_k)$\n",
    "\n",
    "*   Список растояний между пространствами $\\|(I - P(U_{k-1}))P(U_{k})\\|_2$\n",
    "\n",
    "В качестве критерия остановки будем использовать величину $\\delta_k$. При значении $\\delta_k \\le tolerance$ алгоритм должен остановиться. При указании `debug=True` печатайте номер текущей итерации и последнюю $\\delta_k$, а также любую дополнительную интересную вам информацию. \n",
    "\n",
    "Используйте реализованные выше функции. Для вычисления фробениусовой нормы разреженной матрицы используйте `norm` из `scipy.sparse.linalg`.\n",
    "\n",
    "**Замечание:** Если вы не реализовали dist_between_subspaces, то вместо третьего списка возращайте None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSt2tZH9GTkM"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import norm as sparse_norm\n",
    "\n",
    "def ALS(A, rank, tolerance=1e-2, debug=False):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: 2D m x n numpy array\n",
    "            rank: required rank of the approximation\n",
    "            tolerance: stop when delta_k is less or equal to it\n",
    "            debug: print debug information on each iteration\n",
    "            \n",
    "        Output\n",
    "            U, VT: m x rank, rank x n numpy arrays forming skeleton decomposition;\n",
    "                   rows of matrix VT are orthonormal\n",
    "            fs: list of f(U_k, VT_k)\n",
    "            deltas: list of f(U_{k-1}, VT_{k-1}) - f(U_k, VT_{k})\n",
    "            dists: list of distances from Im(U_{k-1}) and Im(U_k)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYKGYPkGGTkM"
   },
   "source": [
    "Запустим метод на матрице `A_train` и посмотрим на убывание функционала от номера итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yma5t_5LGTkN"
   },
   "outputs": [],
   "source": [
    "rank = 30\n",
    "U_als, VT_als, fs, deltas, dists = ALS(A_train, rank, 0.1, debug=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 5), ncols=2)\n",
    "\n",
    "axs[0].plot(fs)\n",
    "axs[1].plot(deltas)\n",
    "axs[1].semilogy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MDLeO4cFjCV"
   },
   "outputs": [],
   "source": [
    "# опционально\n",
    "\n",
    "plt.plot(dists);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA1WkWSIGTkN"
   },
   "source": [
    "### c. (10 баллов) Сравнение с рандомизированным SVD и разреженным SVD\n",
    "\n",
    "Примените рандомизированное SVD из sklearn, а также SVD из scipy, поддерживающее разреженные матрицы (используйте тот же ранг 30, что и для ALS). Сравните все три результата по значению функционала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71L_5u63GTkN"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "A_norm = sparse_norm(A_train)\n",
    "\n",
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmA27YeGGTkN"
   },
   "source": [
    "### d. (25 баллов) Построение рекомендаций\n",
    "  1. **(10 баллов)** Научимся рекомендовать пользователям из тестовой группы фильмы на основе части их оценок. Напишем функцию `recommend`, которая будет принимать матрицу $V$ из нашей модели, матрицу `(user_id, movie_id) -> binary rating` (то есть того же формата, что и наша основная матрица `A`), а также число `pred_am` &mdash; количество фильмов, которые мы хотим порекомендовать. Возвращать функция будет top-`pred_am` рекомендаций, то есть `pred_am` фильмов, которые могут пользователю понравиться, в порядке убывания предсказанной привлекательности.\n",
    "\n",
    "  Чтобы построить рекомендацию, необходимо ортогонально спроецировать вектор, соответствующий новому пользователю (про которого мы знаем часть оценок), на пространство $L$, образуемое строками матрицы $V^\\top$. Иными словами, мы должны взять ближайший вектор из $L$. Он будет содержать предсказанные нашей моделью рейтинги. Дальше дело техники :) Но не забудьте, что `score_mat` содержит векторы, соответствующие не одному пользователю, а батчу из `batch_size` пользователей. Хотя и (слава numpy) код остаётся почти дословно такой же. **Подсказка:** используйте функцию `np.argsort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WZrWySAGTkO"
   },
   "outputs": [],
   "source": [
    "def recommend(score_mat, pred_am, V):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            score_mat: sparse batch_size x n_movies array\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array\n",
    "            \n",
    "        Output\n",
    "            recs: batch_size x pred_am array of movies to recommend, with descending predicted rating\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgiVdYYAGTkO"
   },
   "source": [
    "Для проверки нашей модели для каждого пользователя из тестовой выборки оценим так называемый **hit rate**. Для этого выбросим одну из его оценок, вызовем функцию `recommend` и посмотрим, попал ли выкинутый фильм в подборку. Если попал &mdash; это hit, иначе не hit. Для того, чтобы эффективно проделать этот эксперимент на всех тестовых данных, сделаем следующее: разобьём тестовую матрицу на батчи по 500 пользователей и будем предсказывать сразу для целого батча. Вычислим вектор размера `n_test`, где для каждого пользователя указано, на каком месте в рекомендованной подборке оказался скрытый фильм (или число `n_recs`, если скрытого фильма не нашлось среди top-n  рекомендаций)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tOq0553GTkO"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "\n",
    "def evaluate_model(A_test, pred_am, V, batch_size=500):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array representing the rating model\n",
    "            batch_size: number of users to build recommendations for in a single call to recommend\n",
    "\n",
    "        Output\n",
    "            hit_idx: list of n_test ints: place of secret movie \n",
    "                     in top-pred_am recommendations (or pred_am if it is missing)\n",
    "    \"\"\"\n",
    "    secrets = []\n",
    "    nonempty_users = []\n",
    "    A_test = A_test.copy()\n",
    "    for user in range(A_test.shape[0]):\n",
    "        _, good, _ = find(A_test[user,:])\n",
    "        if len(good) == 0:\n",
    "            continue\n",
    "        nonempty_users.append(user)\n",
    "        secret = np.random.choice(good, 1)[0]\n",
    "        A_test[user, secret] = 0\n",
    "        secrets.append(secret)\n",
    "    hit_idx = []\n",
    "    for i in range(0, len(nonempty_users), batch_size):\n",
    "        # Build recomendations for a batch.\n",
    "        recommendations = recommend(A_test[nonempty_users[i:i + batch_size], :], pred_am + 1, V)\n",
    "        # Place secret in the last column so that the following .argmax finds it.\n",
    "        recommendations[:,-1] = secrets[i: i + batch_size]\n",
    "        # Find secret among the recommendations and place its index into batch_hit_idx.\n",
    "        batch_hit_idx = (recommendations == np.array([secrets[i:i + batch_size]]).T).argmax(1)\n",
    "        hit_idx += batch_hit_idx.tolist()\n",
    "    return hit_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2NZjgRdGTkP"
   },
   "source": [
    "  2. **(15 баллов)** Научимся вычислять hit rate для данной модели и заданного количества top-n рекомендаций. Для этого напишем функцию `get_hit_rates`, которая будет принимать $V$ из нашей модели, вектора оценок для новых пользователей `A_test` и список натуральных чисел `pred_ams`. Для каждого из этих чисел необходимо посчитать средний hit rate по всем пользователям из `A_test`, то есть, например, для `pred_ams == [5, 10, 20]` нужно вернуть список средних хитрейтов для top-5, top-10 и top-20. **Обратите внимание:** вызвать функцию `evaluate_model` нужно только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUW5e6IgGTkP"
   },
   "outputs": [],
   "source": [
    "def get_hit_rates(A_test, pred_ams, V):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users \n",
    "            pred_ams: list of ints: number of top recomendations to evaluate hit rate for\n",
    "            V: 2D numpy array representing the rating model\n",
    "        Output\n",
    "            hit_rates: list of float: hit rate for each element of n_recs\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRdKpRy2GTkP"
   },
   "source": [
    "Проверьте себя: вычислите хитрейт на top-10 рекомендаций для Sparse SVD ранга 30. Чтобы вычисления рекомендаций были побыстрее, используйте не всю матрицу `A_test`, а, например, первые 1000 строк. Хитрейт должен получится в районе 12-15%. Самое время подебажить своё решение, если числа сильно расходятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elF_WFMOGTkP"
   },
   "outputs": [],
   "source": [
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0qfki6qGTkQ"
   },
   "source": [
    "Теперь можно построить графики зависимости hit rate от количества рекомендаций, а также от ранга модели. Сравним результаты, которые дают три алгоритма: ALS, Sparse SVD и рандомизированный SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEL4vVfyGTkQ"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "pred_ams = list(range(5, 101, 5))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "_, (ax_svd, ax_als, ax_rand) = plt.subplots(1,3,figsize=(20, 4),sharey=True)\n",
    "\n",
    "ax_svd.set_title(\"SVD\")\n",
    "ax_svd.set_ylabel(\"Hit rate\")\n",
    "ax_als.set_title(\"ALS\")\n",
    "ax_rand.set_title(\"Rand SVD\")\n",
    "for rank in [5, 25, 50]:\n",
    "    _, _, VT_svd = svds(A_train, k=rank)\n",
    "    _, VT_als, _, _, _ = ALS(A_train, rank)\n",
    "    _, _, VT_rand = randomized_svd(A_train, rank)\n",
    "    for VT, ax in zip([VT_svd, VT_als, VT_rand], [ax_svd, ax_als, ax_rand]):\n",
    "        ax.set_xlabel(\"Number of recomendations\")\n",
    "        hit_rates = get_hit_rates(A_test[:1000,:], pred_ams, VT.T)\n",
    "        line, = ax.plot(pred_ams, hit_rates)\n",
    "        line.set_label('rank = {}'.format(rank))\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5syrgrHggLt"
   },
   "source": [
    "**YOUR WORDS GO HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Aw-QdjtGTkQ"
   },
   "source": [
    "Какой ранг приближения оказался оптимальным для нашей модели в случае каждого алгоритма?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKW0NkY2ci52"
   },
   "source": [
    "## Бонус. Higher-order SVD (100 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sueW4YISk5Ga"
   },
   "source": [
    "**В бонусе разрешается использовать циклы только по размерности.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlWRcHRfGTkQ"
   },
   "source": [
    "1. (**20 баллов**) Напишите функцию ```tuck2full(G, Us)```, возвращающую полный тензор размера $n_1\\times n_2 \\times \\ldots \\times n_d$ по его разложению Таккера. Предусмотрите, чтобы функция работала и в случае, если в матрицах $U_1,U_2, \\ldots, U_d$ строк меньше, чем столбцов. Вместо циклов используйте функцию ```np.einsum```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-Oq1V5WGTkR"
   },
   "outputs": [],
   "source": [
    "def tuck2full(G, Us):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "\n",
    "        Output\n",
    "            A: d-dimensional numpy array of the size (n1, n2, ..., nd)\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fBi08IeGTkR"
   },
   "source": [
    "2. (**35 баллов**) Реализуйте higher-order SVD алгоритм для нахождения разложения Таккера данного $d$-мерного массива $A\\in\\mathbb{R}^{n_1\\times \\ldots \\times n_d}$. Алгоритм должен находить малоранговое приближение $A$ с относительной точностью не хуже $\\varepsilon$ во Фробениусовой норме. Функция должна вернуть ядро и факторы Таккера у приближающего тензора. Для получения ядра Таккера будет удобно воспользоваться функцией ```tuck2full```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bmOtAq8GTkR"
   },
   "outputs": [],
   "source": [
    "def hosvd(A, eps):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: 3D numpy array\n",
    "            eps: accuracy of Tucker approximation\n",
    "\n",
    "        Output\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KU-1RaGcGTkR"
   },
   "source": [
    "3. (**5 баллов**) Примените функцию ```hosvd``` к тензору размера $25 \\times 50 \\times 75 \\times 100$ с элементами\n",
    "$$\n",
    "    a_{ijkl} = \\frac{1}{i + j + k + l + 1}, \\quad i,j,k,l=0,1,...\n",
    "$$\n",
    "для малорангового приближения с точностью $10^{-6}$. Массив $A$ соберите с помощью функции ```np.meshgrid```. Напечатайте получившиеся ранги и относительную ошибку полученного малорангового приближения (для этого используйте функцию ```tuck2full```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op7t7XOpGTkR"
   },
   "outputs": [],
   "source": [
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEYomrX1i0gC"
   },
   "source": [
    "4. (**15 баллов**) Докажите, что норма Фробениуса приближения HOSVD $A'$ совпадает с её ядром Таккера $G'$:\n",
    "\n",
    "$$\n",
    "  \\|A'\\|_F = \\|G'\\|_F\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ7oLmRvjRis"
   },
   "source": [
    "**YOUR WORDS GO HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bChF9TCnkhxc"
   },
   "source": [
    "5. (**25 баллов**) Для заданного таккеровского разложения напишите функцию вычисления его нормы. Примените ее к разложению тензора размера 10000 x 10000 x 10000 со случайными Таккеровскими факторами и ядром мультилинейного ранга (10, 10, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtAEo92Tllxz"
   },
   "outputs": [],
   "source": [
    "def tuck_norm(G, Us):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "\n",
    "        Output\n",
    "            norm: Frobenius norm of A = [G; U1 ... Ud]\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of hw2_practice_fmatcomp22.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
